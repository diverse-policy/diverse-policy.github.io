<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Diverse Policy Learning via Random Obstacle Deployment for Zero-Shot Adaptation</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="#abstract">Abstract</a>
      <a class="navbar-item" href="#components">Components</a>
      <a class="navbar-item" href="#experiments">Experiments</a>
      <a class="navbar-item" href="#citation">Citation</a>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h1 class="title">Diverse Policy Learning via Random Obstacle Deployment for Zero-Shot Adaptation</h1>
      <p class="subtitle">IEEE Robotics and Automation Letters (RA-L), 2025</p>
      <div class="content">
        <p><strong>Authors:</strong> Seokjin Choi, Yonghyeon Lee, Seungyeon Kim, Che-Sang Park, Himchan Hwang, Frank C. Park</p>
        <a href="https://github.com/your-github-repo" class="button is-dark">Code on GitHub</a>
      </div>
    </div>
  </div>
</section>

<section id="abstract" class="section">
  <div class="container">
    <h2 class="title">Abstract</h2>
    <p>
      In this paper, we propose a novel reinforcement learning framework that enables zero-shot policy adaptation in environments with unseen, dynamically changing obstacles. 
      Adopting the idea that learning a policy capable of generating diverse actions is key to achieving such adaptability, our primary contribution is a novel learning algorithm that incorporates random obstacle deployment, enabling the policy to explore and learn diverse actions. 
      This method overcomes the limitations of existing diverse policy learning approaches, which primarily rely on mutual information maximization to increase diversity. 
      Experiments demonstrate that the proposed method generates significantly more diverse actions and adapts better to dynamically changing environments, making it highly effective for tasks with varying constraints such as moving obstacles.
    </p>
  </div>
</section>

<section id="components" class="section">
  <div class="container">
    <h2 class="title">Key Components</h2>

    <h3 class="title is-4">1. Policy</h3>
    <p>
      The policy is designed to output diverse actions based on latent skills while ensuring adaptability to dynamically changing environments. During training, random obstacle deployment is used to promote exploration and the learning of diverse trajectories. 
    </p>

    <h3 class="title is-4">2. Motion Predictor</h3>
    <p>
      The motion predictor forecasts the state trajectory resulting from a given action. This enables the filtering of unsafe actions by predicting which trajectories would violate environmental constraints. 
    </p>

    <h3 class="title is-4">3. Latent Skill Sampler</h3>
    <p>
      A state-dependent latent skill sampler generates diverse skill variables for each state. These skills are used to condition the policy and produce a wide range of actions that can adapt to unseen constraints.
    </p>
  </div>
</section>

<section id="experiments" class="section">
  <div class="container">
    <h2 class="title">Experiments</h2>
    <p>We conducted experiments in four reinforcement learning environments: Push-T, Ant, Reacher, and Swimmer.</p>
    <figure>
      <img src="./static/images/experiment_results.png" alt="Experiment Results">
      <figcaption>Performance comparison in unseen environments with dynamically changing obstacles.</figcaption>
    </figure>
  </div>
</section>

<section id="citation" class="section">
  <div class="container">
    <h2 class="title">Citation</h2>
    <pre><code>
@article{choi2025diverse,
  title={Diverse Policy Learning via Random Obstacle Deployment for Zero-Shot Adaptation},
  author={Choi, Seokjin and Lee, Yonghyeon and Kim, Seungyeon and Park, Che-Sang and Hwang, Himchan and Park, Frank C},
  journal={IEEE Robotics and Automation Letters},
  year={2025}
}
    </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="content has-text-centered">
    <p>Page created for the paper: <em>Diverse Policy Learning via Random Obstacle Deployment for Zero-Shot Adaptation</em>.</p>
  </div>
</footer>

</body>
</html>